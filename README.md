# ğŸ“„ ChatPDF â€“ End-to-End RAG Application with Streamlit & LangChain

ChatPDF is a **full end-to-end Retrieval-Augmented Generation (RAG) application** that allows users to upload PDF documents and ask natural language questions.  
The system retrieves relevant content from the PDF using **FAISS vector search** and generates answers using **LLMs (OpenAI or Google Gemini)**.

This project is built using the **latest LangChain Runnable API**, optimized with **Streamlit caching**, and designed to be **cost-efficient, scalable, and resume-ready**.

---

## ğŸ”¥ Why This Project?

- Demonstrates **real-world RAG architecture**
- Handles **API quota limitations** correctly
- Uses **local embeddings** to avoid cost issues
- Shows **production-level optimization**
- Ideal for **Data Scientist / ML Engineer / GenAI roles**

---

## âœ¨ Key Features

- ğŸ“‚ Upload and process PDF documents
- ğŸ” Semantic search using FAISS
- ğŸ§  Local HuggingFace embeddings (no API cost)
- ğŸ¤– LLM support:
  - OpenAI GPT models
  - Google Gemini
- âš¡ Fast performance with Streamlit caching
- ğŸ” Secure environment variable handling
- ğŸ—ï¸ Clean, modular, maintainable code
- ğŸ’¼ Resume and interview ready

---

## ğŸ§  End-to-End Architecture

User Uploads PDF
â†“
PDF Text Extraction (pypdf)
â†“
Text Chunking (CharacterTextSplitter)
â†“
Local Embeddings (HuggingFace)
â†“
FAISS Vector Store
â†“
Retriever (Top-K Similarity Search)
â†“
Prompt + Context
â†“
LLM (OpenAI / Gemini)
â†“
Answer Displayed in Streamlit UI


---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-----|-----------|
Frontend | Streamlit |
LLM Orchestration | LangChain (Runnable API) |
Vector Store | FAISS |
Embeddings | HuggingFace Sentence Transformers |
LLMs | OpenAI GPT / Google Gemini |
Language | Python |

---

## ğŸ“‚ Project Structure

chatpdf/
â”‚
â”œâ”€â”€ chatbot.py # Main Streamlit application
â”œâ”€â”€ requirements.txt # Project dependencies
â”œâ”€â”€ .gitignore # Ignored files & secrets
â”œâ”€â”€ .env # API keys (not committed)
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ venv/ # Virtual environment (ignored)

---

## âš™ï¸ Installation (End-to-End)

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/<your-username>/chatpdf-streamlit-langchain.git
cd chatpdf-streamlit-langchain
Create Virtual Environment (Windows)
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ“¦ requirements.txt
streamlit
pypdf
python-dotenv

langchain
langchain-core
langchain-community
langchain-text-splitters

langchain-openai
langchain-google-genai

sentence-transformers
faiss-cpu

ğŸ” Environment Variables Setup

Create a .env file in the project root:

OPENAI_API_KEY=your_openai_api_key
GOOGLE_API_KEY=your_google_api_key


âš ï¸ Never commit .env to GitHub
(It is already ignored via .gitignore)

â–¶ï¸ Run the Application
streamlit run chatbot.py


Open in browser:

http://localhost:8501

ğŸ§ª How the Application Works (Step-by-Step)

User uploads a PDF

Text is extracted using pypdf

Text is split into overlapping chunks

Chunks are embedded using local HuggingFace embeddings

FAISS indexes the embeddings

User asks a question

Relevant chunks are retrieved

LLM generates an answer using retrieved context

Answer is displayed in the UI

âš¡ Performance Optimizations

Cached PDF loading (st.cache_data)

Cached text splitting

Cached FAISS vector store (st.cache_resource)

Prevents recomputation on every UI interaction

ğŸš¨ Common Issues & Fixes
âŒ App is slow

âœ… Fixed using Streamlit caching

âŒ OpenAI / Gemini quota exceeded

âœ… Local HuggingFace embeddings used

âŒ LangChain import errors

âœ… Migrated to latest modular LangChain packages

âŒ Windows pip install errors

âœ… Single-line pip command used

ğŸ§  Design Decisions (Important)

Local embeddings â†’ avoids billing & rate limits

Runnable API â†’ future-proof LangChain usage

FAISS â†’ fast similarity search

Environment-based secrets â†’ secure & professional

ğŸ“Œ Resume Bullet (Use This)

Built an end-to-end ChatPDF application using Streamlit, LangChain, FAISS, and HuggingFace embeddings to enable retrieval-augmented question answering over PDF documents, optimizing performance with caching and modern Runnable architecture.

ğŸš€ Future Enhancements

Streaming token responses

Source citations (page numbers)

Conversational memory

Multi-document support

Cloud deployment (Streamlit Cloud / Render)

ğŸ“œ License

MIT License

ğŸ™Œ Acknowledgements

Streamlit

LangChain

HuggingFace

FAISS


---

## âœ… FINAL RESULT

âœ” Complete end-to-end documentation  
âœ” Recruiter-friendly  
âœ” Clear execution flow  
âœ” Explains **why**, not just **how**  
âœ” Professional GitHub presence

## ğŸ“¸ Application Screenshots

### ğŸ  Home Screen
![Home Screen](assets/front_end.png)


If you want next:
- **`DEPLOY README`** â†’ Add deployment steps  
- **`ARCH DIAGRAM`** â†’ Visual diagram for README  
- **`RESUME SECTION`** â†’ Full resume project write-up  

If someone like this github repo and feels useful, stay connected.
